{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "batch_size: 512\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "from torch.autograd import Variable, grad\n",
    "\n",
    "# 1. 환경 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "batch_size = 512\n",
    "print(f\"batch_size: {batch_size}\")\n",
    "\n",
    "# 2. 데이터 준비 (Fashion MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./Fashion_MNIST_dataset',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. WGAN-GP 아키텍처 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, img_dim=784):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "class Critic(nn.Module):  # Discriminator를 Critic으로 변경\n",
    "    def __init__(self, img_dim=784):\n",
    "        super(Critic, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(256, 1)  # 마지막에 활성화 함수 제거\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]  Loss_C: -2.0705  Loss_G: -10.0021\n",
      "Epoch [10/100]  Loss_C: -2.8403  Loss_G: -3.0662\n",
      "Epoch [20/100]  Loss_C: -1.8603  Loss_G: -4.3060\n",
      "Epoch [30/100]  Loss_C: -2.0045  Loss_G: -0.0236\n",
      "Epoch [40/100]  Loss_C: -1.8784  Loss_G: -0.7376\n",
      "Epoch [50/100]  Loss_C: -1.5112  Loss_G: -1.4654\n",
      "Epoch [60/100]  Loss_C: -1.3396  Loss_G: -1.1964\n",
      "Epoch [70/100]  Loss_C: -1.5365  Loss_G: -1.9615\n",
      "Epoch [80/100]  Loss_C: -1.5113  Loss_G: -1.5102\n",
      "Epoch [90/100]  Loss_C: -1.4593  Loss_G: -1.5154\n",
      "Epoch [100/100]  Loss_C: -1.4294  Loss_G: -3.6116\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 초기화 및 설정\n",
    "noise_dim = 100\n",
    "img_dim = 28*28  # Fashion MNIST 이미지 크기\n",
    "features_g = 64\n",
    "features_d = 64\n",
    "lr, b1, b2 = 3e-5, 0.0, 0.9\n",
    "num_epochs = 100\n",
    "n_critic = 5  # Number of critic iterations per generator iteration\n",
    "lambda_gp = 10  # Gradient penalty lambda hyperparameter\n",
    "\n",
    "generator = Generator(noise_dim, img_dim).to(device)\n",
    "critic = Critic(img_dim).to(device)\n",
    "\n",
    "# Initialize weights\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.detach(), 0.0, 0.02)\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.detach(), 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.detach(), 0)\n",
    "\n",
    "generator.apply(weights_init)\n",
    "critic.apply(weights_init)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_C = torch.optim.Adam(critic.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# 5. Gradient Penalty 함수 정의\n",
    "def compute_gradient_penalty(critic, real, fake, device=\"cpu\"):\n",
    "    batch_size = real.size(0)\n",
    "    epsilon = torch.rand(batch_size, 1, device=device, requires_grad=True)\n",
    "    interpolated = epsilon * real + (1 - epsilon) * fake\n",
    "    interpolated.requires_grad_(True)\n",
    "    \n",
    "    critic_interpolated = critic(interpolated)\n",
    "    \n",
    "    gradients = grad(\n",
    "        outputs=critic_interpolated,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=torch.ones_like(critic_interpolated),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "    gradient_penalty = lambda_gp * ((gradient_norm - 1) ** 2).mean()\n",
    "    \n",
    "    return gradient_penalty\n",
    "\n",
    "# 5. 학습 루프 및 데이터 수집\n",
    "# 5.1. 결과 저장을 위한 폴더 생성\n",
    "results_dir = './results_dir/WGAN_GP'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "G_losses = []\n",
    "C_losses = []\n",
    "sample_images = []\n",
    "\n",
    "# fixed noise 생성\n",
    "fixed_noise = torch.randn(16, noise_dim).to(device)\n",
    "\n",
    "# 5.2. 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(train_loader):\n",
    "        real = real.view(-1, img_dim).to(device)\n",
    "        batch_size_current = real.size(0)\n",
    "        \n",
    "        ## ---------------------\n",
    "        ##  Train Critic\n",
    "        ## ---------------------\n",
    "        for _ in range(n_critic):\n",
    "            noise = torch.randn(batch_size_current, noise_dim).to(device)\n",
    "            fake = generator(noise)\n",
    "            \n",
    "            critic_real = critic(real)\n",
    "            critic_fake = critic(fake.detach())\n",
    "            \n",
    "            loss_C = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "            \n",
    "            # Gradient penalty\n",
    "            loss_C += compute_gradient_penalty(critic, real, fake.detach(), device=device)\n",
    "            \n",
    "            optimizer_C.zero_grad()\n",
    "            loss_C.backward()\n",
    "            optimizer_C.step()\n",
    "        \n",
    "        ## ---------------------\n",
    "        ##  Train Generator\n",
    "        ## ---------------------\n",
    "        noise = torch.randn(batch_size_current, noise_dim).to(device)\n",
    "        fake = generator(noise)\n",
    "        # Generator loss aims to maximize critic's output for fake samples\n",
    "        loss_G = -torch.mean(critic(fake))\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "    G_losses.append(loss_G.item())\n",
    "    C_losses.append(loss_C.item())\n",
    "    \n",
    "    if epoch == 0 or (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss_C: {loss_C.item():.4f}  Loss_G: {loss_G.item():.4f}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_images = generator(fixed_noise).reshape(-1, 1, 28, 28).detach().cpu()\n",
    "            sample_images.append(fake_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 시각화\n",
    "# 6.1. 손실 곡선 시각화 및 저장\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Critic Loss During Training (WGAN-GP)\")\n",
    "plt.plot(G_losses, label=\"Generator Loss\")\n",
    "plt.plot(C_losses, label=\"Critic Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(results_dir, \"loss_curve_wgan_gp.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 6.2. 생성된 이미지 시각화 및 저장\n",
    "for idx, images in enumerate(sample_images):\n",
    "    grid = vutils.make_grid(images, nrow=4, normalize=True)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(f\"Generated Images at Epoch {max(idx*10, 1)}\")\n",
    "    plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "    plt.axis(\"off\")\n",
    "    # 이미지 저장\n",
    "    plt.savefig(os.path.join(results_dir, f\"generated_epoch_{max(idx*10, 1)}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
