{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "batch_size: 512\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "from torch.autograd import Variable, grad\n",
    "\n",
    "# 1. 환경 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "batch_size = 512\n",
    "print(f\"batch_size: {batch_size}\")\n",
    "\n",
    "# 2. 데이터 준비 (Fashion MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),  # Resize to 32x32 for DCGAN\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./Fashion_MNIST_dataset',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. WDCGAN-GP 아키텍처 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, channels_img=1, features_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # Input: N x noise_dim x 1 x 1\n",
    "            nn.ConvTranspose2d(noise_dim, features_g * 8, kernel_size=4, stride=1, padding=0, bias=False),  # 4x4\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 8, features_g * 4, kernel_size=4, stride=2, padding=1, bias=False),  # 8x8\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, kernel_size=4, stride=2, padding=1, bias=False),  # 16x16\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 2, features_g, kernel_size=4, stride=2, padding=1, bias=False),  # 32x32\n",
    "            nn.BatchNorm2d(features_g),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g, channels_img, kernel_size=3, stride=1, padding=1, bias=False),  # 32x32\n",
    "            nn.Tanh()\n",
    "            # Output: (channels_img) x32x32\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, channels_img=1, features_d=64):\n",
    "        super(Critic, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # Input: (channels_img) x32x32\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1, bias=False),  # 16x16\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(features_d, features_d * 2, kernel_size=4, stride=2, padding=1, bias=False),  # 8x8\n",
    "            nn.BatchNorm2d(features_d * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(features_d * 2, features_d * 4, kernel_size=4, stride=2, padding=1, bias=False),  # 4x4\n",
    "            nn.BatchNorm2d(features_d * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(features_d * 4, features_d * 8, kernel_size=4, stride=2, padding=1, bias=False),  # 2x2\n",
    "            nn.BatchNorm2d(features_d * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=2, stride=1, padding=0, bias=False)  # 1x1\n",
    "            # No activation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]  Loss_C: -7.4389  Loss_G: -2.0688\n",
      "Epoch [10/100]  Loss_C: -197.7918  Loss_G: 111.1652\n",
      "Epoch [20/100]  Loss_C: -628.8533  Loss_G: 327.8903\n",
      "Epoch [30/100]  Loss_C: -1277.9586  Loss_G: 668.4132\n",
      "Epoch [40/100]  Loss_C: -140.6190  Loss_G: 1112.9521\n",
      "Epoch [50/100]  Loss_C: -3168.7153  Loss_G: 1634.6560\n",
      "Epoch [60/100]  Loss_C: -4388.1484  Loss_G: 2319.5256\n",
      "Epoch [70/100]  Loss_C: -6049.3940  Loss_G: 3035.3926\n",
      "Epoch [80/100]  Loss_C: -7649.5435  Loss_G: 3806.7280\n",
      "Epoch [90/100]  Loss_C: -9490.2695  Loss_G: 4625.8105\n",
      "Epoch [100/100]  Loss_C: -10862.4346  Loss_G: 5124.2451\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 초기화 및 설정\n",
    "noise_dim = 100\n",
    "channels_img = 1  # Grayscale images\n",
    "features_g = 64\n",
    "features_d = 64\n",
    "lr, b1, b2 = 3e-5, 0.0, 0.9\n",
    "num_epochs = 100\n",
    "n_critic = 5  # Number of critic iterations per generator iteration\n",
    "lambda_gp = 10  # Gradient penalty lambda hyperparameter\n",
    "\n",
    "generator = Generator(noise_dim, channels_img, features_g).to(device)\n",
    "critic = Critic(channels_img, features_d).to(device)\n",
    "\n",
    "# Initialize weights\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "generator.apply(weights_init)\n",
    "critic.apply(weights_init)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_C = torch.optim.Adam(critic.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# 5. Gradient Penalty 함수 정의\n",
    "def compute_gradient_penalty(critic, real, fake, device=\"cpu\"):\n",
    "    batch_size = real.size(0)\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1, device=device, requires_grad=True)\n",
    "    interpolated = epsilon * real + (1 - epsilon) * fake\n",
    "    interpolated.requires_grad_(True)\n",
    "    \n",
    "    critic_interpolated = critic(interpolated)\n",
    "    \n",
    "    gradients = grad(\n",
    "        outputs=critic_interpolated,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=torch.ones_like(critic_interpolated),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "    gradient_penalty = lambda_gp * ((gradient_norm - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "# 6. 학습 루프 및 데이터 수집\n",
    "# 6.1. 결과 저장을 위한 폴더 생성\n",
    "results_dir = './results_dir/WDCGAN-GP'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "G_losses = []\n",
    "C_losses = []\n",
    "sample_images = []\n",
    "\n",
    "# fixed noise 생성\n",
    "fixed_noise = torch.randn(16, noise_dim, 1, 1).to(device)\n",
    "\n",
    "# 6.2. 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(train_loader):\n",
    "        real = real.to(device)\n",
    "        batch_size_curr = real.size(0)\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Critic\n",
    "        # ---------------------\n",
    "        for _ in range(n_critic):\n",
    "            # Sample noise and generate fake images\n",
    "            noise = torch.randn(batch_size_curr, noise_dim, 1, 1, device=device)\n",
    "            fake = generator(noise)\n",
    "            \n",
    "            # Compute critic scores\n",
    "            critic_real = critic(real)\n",
    "            critic_fake = critic(fake.detach())\n",
    "            \n",
    "            # Compute gradient penalty\n",
    "            gp = compute_gradient_penalty(critic, real, fake.detach(), device=device)\n",
    "            \n",
    "            # WDCGAN-GP loss for critic\n",
    "            loss_C = -(torch.mean(critic_real) - torch.mean(critic_fake)) + gp\n",
    "            \n",
    "            # Backprop and optimize\n",
    "            optimizer_C.zero_grad()\n",
    "            loss_C.backward()\n",
    "            optimizer_C.step()\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        # Generate fake images\n",
    "        noise = torch.randn(batch_size_curr, noise_dim, 1, 1, device=device)\n",
    "        fake = generator(noise)\n",
    "        \n",
    "        # Compute critic scores for fake images\n",
    "        critic_fake = critic(fake)\n",
    "        \n",
    "        # WDCGAN-GP loss for generator\n",
    "        loss_G = -torch.mean(critic_fake)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "    # Append losses for visualization\n",
    "    G_losses.append(loss_G.item())\n",
    "    C_losses.append(loss_C.item())\n",
    "    \n",
    "    # Print losses and save samples at intervals\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss_C: {loss_C.item():.4f}  Loss_G: {loss_G.item():.4f}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake_images = generator(fixed_noise).detach().cpu()\n",
    "            sample_images.append(fake_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 시각화\n",
    "# 7.1. 손실 곡선 시각화 및 저장\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Critic Loss During Training (WDCGAN-GP)\")\n",
    "plt.plot(G_losses, label=\"Generator Loss\")\n",
    "plt.plot(C_losses, label=\"Critic Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(results_dir, \"loss_curve_wdcgan_gp.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 7.2. 생성된 이미지 시각화 및 저장\n",
    "for idx, images in enumerate(sample_images):\n",
    "    grid = vutils.make_grid(images, nrow=4, normalize=True)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(f\"Generated Images at Epoch {max(idx*10, 1)}\")\n",
    "    plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "    plt.axis(\"off\")\n",
    "    # 이미지 저장\n",
    "    plt.savefig(os.path.join(results_dir, f\"generated_epoch_{max(idx*10, 1)}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
